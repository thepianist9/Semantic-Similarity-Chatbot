{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "XYaOlN9zRAn4",
    "outputId": "386e1897-b942-4ff3-c0e1-fd7f90291b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q_HHp3xRNtA"
   },
   "source": [
    "It turns out that spaCy requires a \"model\" file, which is a bundle of statistical information that allows the library to parse text into words and parts of speech. While spaCy comes with a model when you install it, that model does *not* include word vectors, so you'll need to download a model that does include them. For English, I recommend `en_core_web_lg`, which you can download and install by running the cell below. (The model file is fairly large and might take a while to download.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "sDFEXEfhRMCB",
    "outputId": "7282e4b7-3d10-455d-adfa-3048d0658282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dave\\anaconda3\\envs\\pythoncpu\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3I9yIqLWSSA9"
   },
   "source": [
    "Once download is complete, <b>restart the colab runtime </b>(to do this in the colab menu, go for Runtime > Restart runtime).<br>\n",
    "The code in the following cell loads `spacy` and the model you just downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RY5ytQYSKZf"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3J9-D9EESjbE",
    "outputId": "c7e1b490-f123-4ac6-93a2-95c31e328e5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.6565e-01,  4.6795e-01,  5.8068e-02,  2.9165e-03, -1.3532e-01,\n",
       "        2.1199e-01,  8.2157e-02, -6.2320e-02, -5.3217e-02,  1.8894e+00,\n",
       "        1.6439e-01,  3.1966e-01, -9.3268e-02,  1.4703e-01,  1.0479e-01,\n",
       "       -1.7459e-01, -4.4935e-01,  1.2442e+00, -1.9939e-01, -3.3135e-01,\n",
       "        3.1638e-01,  9.2198e-03,  2.1116e-01, -3.8205e-01, -1.1604e-01,\n",
       "        2.6201e-01,  2.7354e-01, -6.7279e-02, -1.9275e-01,  2.3613e-02,\n",
       "        2.2156e-01,  2.3550e-01,  2.6286e-02,  2.5266e-01,  2.8450e-03,\n",
       "       -2.5412e-01,  2.5801e-01, -2.1384e-01, -1.5835e-01, -1.4999e-01,\n",
       "        1.8592e-01, -4.6072e-02, -7.5218e-02,  3.1008e-01,  1.3776e-01,\n",
       "        5.6249e-01, -4.1056e-01,  5.7491e-01,  3.9835e-01, -5.5174e-02,\n",
       "       -3.5544e-02,  2.0639e-02,  1.0778e-01, -4.0423e-02,  1.5546e-01,\n",
       "        5.8229e-02,  4.5573e-02,  1.5203e-01,  2.2158e-01,  1.4574e-01,\n",
       "        5.0506e-03, -4.5902e-01, -7.5091e-01,  1.2658e-01, -1.6015e-01,\n",
       "       -3.6611e-01,  1.1662e-01,  2.1730e-01,  4.2705e-01,  2.2346e-02,\n",
       "        1.3270e-01,  7.1102e-03,  4.2529e-02, -8.5767e-03,  1.3270e-02,\n",
       "       -5.4661e-02, -6.2519e-02, -3.2131e-02, -6.1688e-01,  2.3254e-01,\n",
       "        5.2426e-01,  2.7106e-01,  4.6270e-01,  5.1616e-01,  2.6395e-01,\n",
       "       -2.2238e-01, -4.3772e-01,  1.6473e-01, -2.1385e-01, -4.0352e-01,\n",
       "       -1.5626e-01,  4.4547e-01, -6.3071e-01,  3.3988e-01,  3.6708e-01,\n",
       "        1.9431e-01, -2.5179e-01,  6.8152e-02, -1.0477e-01,  2.1630e-01,\n",
       "        5.8011e-02, -4.9235e-01,  6.1183e-02, -2.9098e-01,  4.2542e-01,\n",
       "       -1.5419e-01,  3.6715e-01, -1.5139e-01,  1.4786e-01, -5.4276e-01,\n",
       "        9.3033e-02, -4.2559e-01,  3.0246e-02, -2.9615e-02,  3.7063e-01,\n",
       "        5.7841e-02, -1.8331e-01,  3.9637e-01,  1.3237e-01,  4.9718e-02,\n",
       "        1.1236e-01,  1.8469e-01, -2.2147e-02, -3.3576e-01,  1.2797e-01,\n",
       "        2.1288e-01, -5.8891e-01, -4.2214e-01,  1.2315e-01, -4.5514e-02,\n",
       "       -1.4740e-01, -3.0441e-01,  8.3328e-02,  5.4008e-02,  3.8701e-02,\n",
       "        2.3431e-01, -2.4651e-01, -5.9651e-02,  3.9942e-02,  9.8232e-02,\n",
       "       -2.7777e+00,  4.2966e-01,  5.4924e-01,  2.9803e-01, -4.6230e-02,\n",
       "       -4.2252e-01, -1.0365e-01, -1.7235e-01,  2.1413e-01, -2.0450e-01,\n",
       "       -2.2627e-01,  1.7994e-01, -7.7341e-02, -8.7296e-02,  1.4048e-01,\n",
       "       -7.0246e-02,  1.4326e-01, -1.9218e-01, -5.7365e-02, -5.3150e-01,\n",
       "        1.1466e-01,  2.1408e-01,  1.0929e-01,  8.1470e-02,  4.6822e-01,\n",
       "        1.1850e-01,  1.9134e-01, -3.6775e-01,  5.1740e-02,  1.9193e-01,\n",
       "       -3.2476e-01,  3.3578e-01,  4.4908e-01,  4.0609e-02, -3.7994e-01,\n",
       "       -1.2334e-01, -4.8406e-01,  6.4413e-03, -2.7863e-01,  6.7770e-02,\n",
       "        2.3558e-01,  1.4641e-01, -1.1901e-01, -4.8438e-02,  5.5389e-02,\n",
       "       -8.0645e-01,  9.0669e-02, -5.0185e-02,  5.3512e-02,  4.8888e-01,\n",
       "       -2.9010e-02,  1.2506e-01,  8.7486e-03,  1.2326e-01, -2.3738e-01,\n",
       "        1.0724e-01,  1.3430e-01, -2.3008e-01,  3.3766e-01, -1.0131e-02,\n",
       "       -3.0800e-01, -4.1941e-01,  3.6675e-01, -1.3184e-01,  1.5199e-01,\n",
       "        2.2037e-01, -2.5005e-01,  4.0681e-01, -8.0808e-02, -4.7393e-02,\n",
       "       -1.3591e-01, -6.9560e-02,  1.6186e-01, -3.8687e-01, -2.4554e-01,\n",
       "        5.4857e-01,  6.5246e-01, -5.8015e-01,  4.4629e-01, -7.1038e-02,\n",
       "       -3.6557e-01,  2.4626e-01, -1.2620e-01,  4.7161e-01,  3.9340e-01,\n",
       "       -1.6209e-01, -1.2871e-01,  4.2189e-01,  2.0447e-01,  2.5336e-01,\n",
       "        2.9942e-02, -3.6477e-01, -6.3115e-02,  1.6702e-01,  1.1295e-03,\n",
       "       -2.9248e-01, -4.1051e-01, -7.8319e-02, -1.9765e-01, -3.6319e-02,\n",
       "       -1.8223e-01,  1.0946e-01, -4.5796e-01,  2.5045e-01,  4.6121e-01,\n",
       "        2.0370e-01, -3.2882e-01, -1.2593e-01, -1.4234e-01,  1.1913e-01,\n",
       "        2.2327e-02, -1.6654e-01, -1.5848e-01, -1.7004e-01, -2.3289e-01,\n",
       "        2.8755e-01,  1.9638e-01,  2.3712e-01, -3.7143e-01, -3.4570e-02,\n",
       "        5.7985e-01, -1.8524e-01,  2.5800e-01, -7.5692e-02, -1.0939e-02,\n",
       "       -2.9612e-02,  3.3647e-01,  1.9022e-02,  2.6089e-01,  7.5997e-01,\n",
       "       -9.7244e-01,  2.3997e-03, -4.7492e-01, -2.5332e-01, -3.6002e-01,\n",
       "       -1.0497e-01, -2.1075e-01, -2.7173e-01,  3.5433e-01,  1.7002e-01,\n",
       "        2.8415e-01, -7.2796e-02, -3.0009e-01,  1.8219e-01, -3.5420e-02,\n",
       "       -6.0116e-02,  3.2760e-01,  2.8918e-01,  1.8939e-01,  1.0067e-03,\n",
       "       -3.6454e-01,  2.7791e-01,  2.0619e-02, -1.8093e-02,  1.6039e-01,\n",
       "       -1.2029e-01,  4.5533e-01,  1.4770e-01,  1.1910e-01,  2.0597e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['amazing'].vector # replace cheese with whatever word you want!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMYW6B-KSXK3"
   },
   "source": [
    "You can look up the word vector for a particular word using spaCy right out the box like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z06aIT2uGxe5"
   },
   "source": [
    "It might not look much, but that list of three hundred numbers is spaCy's idea of what \"cheese\" means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q65ocsUUSsJV"
   },
   "source": [
    "### Parsing a corpus of conversations\n",
    "\n",
    "So now we need some data for the bot. In particular, we need some conversations: the text of the turns along with information about which turn is in response to which. Fortunately, some researchers at Cornell University have made available a very interesting corpus of conversations: [The Cornell Movie Dialog Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html), containing \"220,579 conversational exchanges between 10,292 pairs of movie characters.\" Very cool. The data is stored in several plain text files, which you can download by running the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4DzyPM9AFjK"
   },
   "outputs": [],
   "source": [
    "!curl -L -O http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnAPBxSnAV89"
   },
   "outputs": [],
   "source": [
    "!unzip cornell_movie_dialogs_corpus.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dAMYW22GNAJ"
   },
   "source": [
    "We'll be working with two files from this corpus. One file (`movie_lines.txt`) has the movie lines themselves, associated with a short unique identifier; another file (`movie_conversations.txt`) has lists of which lines occurred together in conversations, in the order in which they occurred. The following two cells parse these two files and create lookup dictionaries that associate unique IDs to lines (`movie_lines`) and each line to the line that follows it (`responses`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MHr4xBS_AfBT"
   },
   "outputs": [],
   "source": [
    "movie_lines = {}\n",
    "for line in open(\"./cornell movie-dialogs corpus/movie_lines.txt\",\n",
    "                 encoding=\"latin1\"):\n",
    "    line = line.strip()\n",
    "    parts = line.split(\" +++$+++ \")\n",
    "    if len(parts) == 5:\n",
    "        movie_lines[parts[0]] = parts[4]\n",
    "    else:\n",
    "        movie_lines[parts[0]] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "arbpjBT5Aj7K"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "responses = {}\n",
    "for line in open(\"./cornell movie-dialogs corpus/movie_conversations.txt\",\n",
    "                 encoding=\"latin1\"):\n",
    "    line = line.strip()\n",
    "    parts = line.split(\" +++$+++ \")\n",
    "    line_ids = json.loads(parts[3].replace(\"'\", '\"'))\n",
    "    for first, second in zip(line_ids[:-1], line_ids[1:]):\n",
    "        responses[first] = second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kdjf5_NTG6_O"
   },
   "source": [
    "Just to make sure everything works, the cell below prints out five random pairs of conversational turns from the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWJd0N2oAsAu"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "for pair in random.sample(responses.items(), 5):\n",
    "    print(\"A:\", movie_lines[pair[0]])\n",
    "    print(\"B:\", movie_lines[pair[1]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vl38pCn4HlL_"
   },
   "source": [
    "### Making a sentence vector\n",
    "\n",
    "To make the sentence vector for each line of dialog, i am using spaCy. The function `sentence_mean` below takes the spaCy object that we loaded earlier (`nlp`) and uses it to tokenize the string that you pass into the function (i.e., break it up into words). It then uses numpy's `mean()` function to find the average of the vectors, producing a new vector. The shape of the resulting vector (i.e., the number of dimensions) should be the same as the shape of the individual word vectors.\n",
    "\n",
    "(Note: I disabled the `tagger` and `parser` parts of spaCy's pipeline to improve performance. We're not using part of speech tags or dependency relations in this chatbot, so there's no reason to spend time calculating them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JizJee4YBAdJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sentence_mean(nlp, s):\n",
    "    if s == \"\":\n",
    "        s = \" \"\n",
    "    doc = nlp(s, disable=['tagger', 'parser'])\n",
    "    return np.mean(np.array([w.vector for w in doc]), axis=0)\n",
    "sentence_mean(nlp, \"This... is a test.\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sN9qQhQvJG-L"
   },
   "source": [
    "### Similarity lookups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppulERZ5Tz5a"
   },
   "outputs": [],
   "source": [
    "!pip install simpleneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X8jODdF-BHxR"
   },
   "outputs": [],
   "source": [
    "from simpleneighbors import SimpleNeighbors\n",
    "\n",
    "nns = SimpleNeighbors(300)\n",
    "for i, line_id in enumerate(random.sample(list(responses.keys()), 10000)):\n",
    "    # show progress\n",
    "    if i % 1000 == 0: print(i, line_id, movie_lines[line_id])\n",
    "    line_text = movie_lines[line_id]\n",
    "    summary_vector = sentence_mean(nlp, line_text)\n",
    "    if np.any(summary_vector):\n",
    "        nns.add_one(line_id, summary_vector)\n",
    "nns.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UOeTbDtL8l3"
   },
   "source": [
    "Let's take it for a spin! The code in the following cell finds the turn most similar to the string in the variable `sentence`. (You can change this string to whatever you want.) It then uses the Simple Neighbors object to find the turn in the database with the most similar vector, and then uses the `responses` lookup to find the *response* to that turn. That response will be our bot's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l656oBJoBLaa"
   },
   "outputs": [],
   "source": [
    "sentence = \"I like making bots.\"\n",
    "picked = nns.nearest(sentence_mean(nlp, sentence), 5)[0]\n",
    "response_line_id = responses[picked]\n",
    "\n",
    "print(\"Your line:\\n\\t\", sentence)\n",
    "print(\"Most similar turn:\\n\\t\", movie_lines[picked])\n",
    "print(\"Response to most similar turn:\\n\\t\", movie_lines[response_line_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI4sCHjmQFfu"
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/aparrish/semanticsimilaritychatbot/archive/master.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nPGClLIPQYBw"
   },
   "source": [
    "Then create a chatbot object, passing in the spaCy language object (`nlp`) and the number of dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWbiYvA-K3xv"
   },
   "outputs": [],
   "source": [
    "from semanticsimilaritychatbot import SemanticSimilarityChatbot\n",
    "chatbot = SemanticSimilarityChatbot(nlp, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvsLgSCKQfIF"
   },
   "source": [
    "The `.add_pair()` method in the object takes two strings: a turn and the response to that turn. We'll get these from the `responses` and `movie_lines` lookups, again sampling ten thousand pairs at random. This cell will take a little while to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaEYCz70KyPg"
   },
   "outputs": [],
   "source": [
    "sample_n = 10000\n",
    "for first_id, second_id in random.sample(list(responses.items()), sample_n):\n",
    "    chatbot.add_pair(movie_lines[first_id], movie_lines[second_id])\n",
    "chatbot.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-sTY8OUK1ju"
   },
   "outputs": [],
   "source": [
    "print(chatbot.response_for(\"Hello computer!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmDFQy-2MiCr"
   },
   "outputs": [],
   "source": [
    "my_turn = \"The weather's nice today, don't you think?\"\n",
    "for i in range(5, 51, 5):\n",
    "    print(\"picking from\", i, \"possible responses:\")\n",
    "    print(chatbot.response_for(my_turn, i))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZw0DgPiRgz4"
   },
   "source": [
    "The Semantic Similarity Chatbot object has a `.save()` method that saves the pre-built database to disk, using a filename prefix you supply. (It saves three different files: `<prefix>.annoy`, `<prefix>-data.pkl`, and `<prefix>-chatbot.pkl`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPgATDpnLTYv"
   },
   "outputs": [],
   "source": [
    "chatbot.save(\"movielines-10k-sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wutboh4MLkja"
   },
   "outputs": [],
   "source": [
    "chatbot = SemanticSimilarityChatbot.load(\"movielines-10k-sample\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6IOQ9DPNrOR"
   },
   "outputs": [],
   "source": [
    "print(chatbot.response_for(\"I'm going to go get some coffee.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCeo-cHdSUxg"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('movielines-10k-sample.annoy')\n",
    "files.download('movielines-10k-sample-data.pkl')\n",
    "files.download('movielines-10k-sample-chatbot.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1wElvooTBjp"
   },
   "source": [
    "## Making it interactive\n",
    "\n",
    "If you're using this notebook in Google Colab, the following cell will create a little interactive interface for chatting with the bot that you just built. Run the two cells below and start typing into the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WSjtkXigBuRo"
   },
   "outputs": [],
   "source": [
    "chatbot_html = \"\"\"\n",
    "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
    "<div id=\"log\"\n",
    "     style=\"box-sizing: border-box;\n",
    "            width: 600px;\n",
    "            height: 32em;\n",
    "            border: 1px grey solid;\n",
    "            padding: 2px;\n",
    "            overflow: scroll;\">\n",
    "</div>\n",
    "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
    "       style=\"box-sizing: border-box;\n",
    "              width: 600px;\n",
    "              margin-top: 5px;\">\n",
    "<script>\n",
    "function paraWithText(t) {\n",
    "    let tn = document.createTextNode(t);\n",
    "    let ptag = document.createElement('p');\n",
    "    ptag.appendChild(tn);\n",
    "    return ptag;\n",
    "}\n",
    "document.querySelector('#typehere').onchange = async function() {\n",
    "    let inputField = document.querySelector('#typehere');\n",
    "    let val = inputField.value;\n",
    "    inputField.value = \"\";\n",
    "    let resp = await getResp(val);\n",
    "    let objDiv = document.getElementById(\"log\");\n",
    "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
    "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
    "    objDiv.scrollTop = objDiv.scrollHeight;\n",
    "};\n",
    "async function colabGetResp(val) {\n",
    "    let resp = await google.colab.kernel.invokeFunction(\n",
    "        'notebook.get_response', [val], {});\n",
    "    return resp.data['application/json']['result'];\n",
    "}\n",
    "async function webGetResp(val) {\n",
    "    let resp = await fetch(\"/response.json?sentence=\" + \n",
    "        encodeURIComponent(val));\n",
    "    let data = await resp.json();\n",
    "    return data['result'];\n",
    "}\n",
    "</script>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHilVz_Yy3Th"
   },
   "outputs": [],
   "source": [
    " import IPython\n",
    "from google.colab import output\n",
    "\n",
    "display(IPython.display.HTML(chatbot_html + \\\n",
    "                             \"<script>let getResp = colabGetResp;</script>\"))\n",
    "\n",
    "def get_response(val):\n",
    "    resp = chatbot.response_for(val)\n",
    "    return IPython.display.JSON({'result': resp})\n",
    "\n",
    "output.register_callback('notebook.get_response', get_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1CJg2lG67KB"
   },
   "source": [
    "If you're not using Colab, try the following two cells to install [Flask](http://flask.pocoo.org) and run a little web server from your notebook that lets you chat with the bot. Click on the link that appears below the second cell to open up the chat in a new window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4hcd0wU4jGK"
   },
   "outputs": [],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25bjOkzX4dC-"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "@app.route(\"/response.json\")\n",
    "def response():\n",
    "    sentence = request.args['sentence']\n",
    "    return jsonify(\n",
    "        {'result': chatbot.response_for(sentence)})\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return chatbot_html + \"<script>let getResp = webGetResp;</script>\"\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "semantic_similarity_chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
